{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36829f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from audtorch.metrics.functional import pearsonr\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21fa582",
   "metadata": {},
   "source": [
    "# 自定义卷积核(特征提取)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c222b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "过去d天X值构成的时序数列和Y值构成的时序数列的相关系数\n",
    "'''\n",
    "\n",
    "class ts_corr(nn.Module):\n",
    "    def __init__(self, d=10, stride=10):\n",
    "        super(ts_corr, self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, X): #X:3D\n",
    "        B, n, T = X.shape # 批量大小，特征数量，时间窗口长度\n",
    "        \n",
    "        w = (T - self.d) // self.stride + 1  # 窗口数量,例如T=10，d=3，stride=2时，w=4\n",
    "        h = n * (n - 1) // 2  # 特征对的数量 C(n, 2)\n",
    "\n",
    "        # 使用 unfold 提取滑动窗口 [形状: (B, n, w, d)]\n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        \n",
    "        #生成C(n,2)组合数\n",
    "        #例如当n=3时，rows = tensor([0,0,1]), cols = tensor([1,2,2])\n",
    "        rows, cols = torch.triu_indices(n, n, offset=1)\n",
    "\n",
    "        # 提取特征对数据得到x和y [形状: (B, h, w, d)]，分别对应batch维度，特征维度，窗口维度，时间维度\n",
    "        #x为([[:,0,:,:],[:,0,:,:],[:,1,:,:])\n",
    "        #y为([[:,1,:,:],[:,2,:,:],[:,2,:,:])\n",
    "        \n",
    "        x = unfolded_X[:, rows, :, :]\n",
    "        y = unfolded_X[:, cols, :, :]\n",
    "        \n",
    "        x_mean = torch.mean(x, dim=3, keepdim=True) #keepdim维持原本维度不变,在维度3做mean\n",
    "        y_mean = torch.mean(y, dim=3, keepdim=True)\n",
    "        \n",
    "        cov = ((x-x_mean)*(y-y_mean)).sum(dim=3) #(B, h, w)\n",
    "        corr = cov / (torch.std(x, dim=3) * torch.std(y, dim=3)+ 1e-8) #分母添加极小值防止除零错误\n",
    "\n",
    "        return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7de5e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "过去d天X值构成的时序数列和Y值构成的时序数列的协方差\n",
    "'''\n",
    "\n",
    "class ts_cov(nn.Module):\n",
    "    def __init__(self, d=10, stride=10):\n",
    "        super(ts_cov, self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, X):\n",
    "        B, n, T = X.shape \n",
    "        \n",
    "        w = (T - self.d) // self.stride + 1  \n",
    "        h = n * (n - 1) // 2  \n",
    "\n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        \n",
    "        rows, cols = torch.triu_indices(n, n, offset=1)\n",
    "\n",
    "        x = unfolded_X[:, rows, :, :]\n",
    "        y = unfolded_X[:, cols, :, :]\n",
    "        \n",
    "        x_mean = torch.mean(x, dim=3, keepdim=True)\n",
    "        y_mean = torch.mean(y, dim=3, keepdim=True)\n",
    "        \n",
    "        cov = ((x-x_mean)*(y-y_mean)).sum(dim=3) \n",
    "\n",
    "        return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4fd7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "过去d天X值构成的时序数列的标准差\n",
    "'''\n",
    "\n",
    "class ts_stddev(nn.Module):\n",
    "    \n",
    "    def __init__(self, d = 10, stride = 10):\n",
    "        super(ts_stddev,self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #input:(B,n,T)，在T维度用unfold展开窗口，变为(B,n,w,d),w为窗口数量会自动计算\n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        #在每个窗口，即d维度上进行std计算\n",
    "        std = torch.std(unfolded_X, dim=3) #输出形状为(B,n,w)\n",
    "        \n",
    "        return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e45b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "过去d天X值构成的时序数列的平均值除以标准差\n",
    "'''\n",
    "\n",
    "class ts_zscore(nn.Module):\n",
    "    \n",
    "    def __init__(self, d = 10, stride = 10):\n",
    "        super(ts_zscore,self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        \n",
    "        mean = torch.mean(unfolded_X, dim=3)\n",
    "        std = torch.std(unfolded_X, dim=3)\n",
    "        zscore = mean / (std + 1e-8)\n",
    "        \n",
    "        return zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a771adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "研报原话为：\n",
    "(X - delay(X, d))/delay(X, d)-1, delay(X, d)为 X 在 d 天前的取值\n",
    "这里可能有误，return为“收益率“，应该是误加了-1\n",
    "为了保持代码一致性，这里计算的是(X - delay(X, d-1))/delay(X, d-1),  delay(X, d-1)为 X 在 d-1 天前的取值\n",
    "在构造卷积核的逻辑上是相似的\n",
    "'''\n",
    "\n",
    "class ts_return(nn.Module):\n",
    "    \n",
    "    def __init__(self, d = 10, stride = 10):\n",
    "        super(ts_return,self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        return1 = unfolded_X[:,:,:,-1] /(unfolded_X[:,:,:,0] + 1e-8) - 1\n",
    "        \n",
    "        return return1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "273d00a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "过去d天X值构成的时序数列的加权平均值，权数为d, d – 1, …, 1(权数之和应为1，需进行归一化处理）\n",
    "其中离现在越近的日子权数越大。 \n",
    "'''\n",
    "\n",
    "class ts_decaylinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, d = 10, stride = 10):\n",
    "        super(ts_decaylinear,self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "        #如下设计的权重系数满足离现在越近的日子权重越大\n",
    "        weights = torch.arange(d, 0, -1, dtype = torch.float32) \n",
    "        weights = weights / weights.sum()\n",
    "        #注册权重，不用在前向传播函数中重复计算\n",
    "        #注册了一个形状为(d,)的一维张量，存放权重系数，以便在forward函数中使用\n",
    "        self.register_buffer('weights', weights) \n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        #view将一维张量广播为4D张量，并在时间维度上，将weights与unfoled_X相乘\n",
    "        decaylinear = torch.sum(unfolded_X * self.weights.view(1,1,1,-1), dim=-1)\n",
    "        \n",
    "        return decaylinear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4fb8c9",
   "metadata": {},
   "source": [
    "# 神经网络结构设计 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d585bd9",
   "metadata": {},
   "source": [
    "原始路径(RawPath)：特征提取层→BN\n",
    "\n",
    "池化路径(PoolPath)：特征提取层→池化层→BN\n",
    "\n",
    "展平→全连接层→预测目标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d72e6b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "原始路径：特征提取层+BN\n",
    "'''\n",
    "class RawPath(nn.Module):\n",
    "    def __init__(self, extractor, bn_dim): #传入参数：卷积核，特征维度\n",
    "        super().__init__()\n",
    "        self.extractor = extractor\n",
    "        self.bn = nn.BatchNorm1d(bn_dim)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        x = self.extractor(X) #extract\n",
    "        x = self.bn(x) #BN\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb98f187",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "池化路径：特征提取层+池化层+BN\n",
    "'''\n",
    "class PoolPath(nn.Module): #传入参数：卷积核，特征维度\n",
    "    def __init__(self, extractor, bn_dim, d_pool=3, s_pool=3):\n",
    "        super().__init__()\n",
    "        self.extractor = extractor\n",
    "        \n",
    "        self.avg_pool = nn.AvgPool1d(d_pool, s_pool)\n",
    "        self.max_pool = nn.MaxPool1d(d_pool, s_pool)\n",
    "        \n",
    "        #每个池化操作bihv使用独立的 BatchNorm 层\n",
    "        #否则会导致三种不同统计量（均值、最大值、最小值）的分布被强制归一化到同一参数\n",
    "        self.bn_avg = nn.BatchNorm1d(bn_dim) \n",
    "        self.bn_max = nn.BatchNorm1d(bn_dim)\n",
    "        self.bn_min = nn.BatchNorm1d(bn_dim)\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.extractor(X)\n",
    "        \n",
    "        x_avg = self.bn_avg(self.avg_pool(x))\n",
    "        x_max = self.bn_max(self.max_pool(x))\n",
    "        x_min = self.bn_min(-self.max_pool(-x))#手动取反实现min_pool\n",
    "        \n",
    "        return torch.cat([x_avg, x_max, x_min], dim = 1) #在特征维度进行拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "631a6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaNet(nn.Module):\n",
    "\n",
    "    def __init__(self, d=10, stride=10, d_pool=3, s_pool=3, n=9, T=30): #池化层窗口d=3，步长stride=3\n",
    "        super(AlphaNet, self).__init__()\n",
    "        \n",
    "        self.d = d \n",
    "        self.stride = stride \n",
    "        h = n * (n - 1) // 2 #手动计算cov和corr特征提取后的特征维度大小\n",
    "        w = (T - d) // stride + 1 #手动计算特征提取层窗口数\n",
    "        w_pool = (w - d_pool) // s_pool + 1 #手动计算池化层窗口数\n",
    "        \n",
    "        #特征提取层列表，共7个\n",
    "        self.extractors = nn.ModuleList([\n",
    "            ts_corr(d,stride),\n",
    "            ts_cov(d,stride),\n",
    "            ts_stddev(d,stride),\n",
    "            ts_zscore(d,stride),\n",
    "            ts_return(d,stride),\n",
    "            ts_decaylinear(d,stride),\n",
    "            nn.AvgPool1d(d,stride) #原研报中的ts_mean\n",
    "        ])\n",
    "        \n",
    "\n",
    "        # 初始化双路径\n",
    "        self.raw_paths = nn.ModuleList()\n",
    "        self.pool_paths = nn.ModuleList()\n",
    "        \n",
    "        # 前两个特征提取器使用h维BN\n",
    "        for i in range(2):\n",
    "            self.raw_paths.append(RawPath(self.extractors[i], h))\n",
    "            self.pool_paths.append(PoolPath(self.extractors[i], h))\n",
    "        \n",
    "        # 后五个特征提取器使用n维BN\n",
    "        for i in range(2, 7):\n",
    "            self.raw_paths.append(RawPath(self.extractors[i], n))\n",
    "            self.pool_paths.append(PoolPath(self.extractors[i], n))\n",
    "\n",
    "        raw_dim = (2*h + 5*n)*w #计算初始路径展平后的维度\n",
    "        pooled_dim = (h*2*3 + n*5*3)*w_pool #计算池化路径展平后的维度\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(raw_dim + pooled_dim, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(30, 1)\n",
    "        )\n",
    "\n",
    "        # 初始化\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                \n",
    "                #截断正态初始化\n",
    "                fan_in = m.weight.size(1)\n",
    "                std = math.sqrt(1.0 / fan_in)  # Xavier方差标准\n",
    "                nn.init.trunc_normal_(m.weight, std=std, a=-2*std, b=2*std)\n",
    "                nn.init.normal_(m.bias, std=1e-6)\n",
    "                \n",
    "                #Kaiming初始化\n",
    "                #nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                \n",
    "                #Xavier初始化\n",
    "                #nn.init.xavier_uniform_(m.weight)\n",
    "                #nn.init.normal_(m.bias, std=1e-6)\n",
    "            \n",
    "    def forward(self, X):\n",
    "        \n",
    "        raw_features = [path(X).flatten(1) for path in self.raw_paths] #原始路径得到的张量进行展平\n",
    "        pool_features = [path(X).flatten(1) for path in self.pool_paths] #池化路径得到的张量进行展平\n",
    "        all_features = torch.cat(raw_features + pool_features, dim=1) \n",
    "        \n",
    "        return self.head(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69633625",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e5988ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (930008, 9, 30)\n",
      "Shape of Y:  (930008,)\n"
     ]
    }
   ],
   "source": [
    "X = np.load('npy_v1/X_fe.npy')\n",
    "Y = np.load('npy_v1/Y_fe.npy')\n",
    "dates = np.load('npy_v1/Y_dates.npy')\n",
    "\n",
    "print('Shape of X: ', X.shape)\n",
    "print('Shape of Y: ', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22321b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "对X进行窗口标准化\n",
    "'''\n",
    "class myDataset(Dataset):\n",
    "    '''\n",
    "    自定义数据集，将原始数据从 numpy arrays 转换成 float 格式的 tensors\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, X, y, scaler = None, is_train = True):\n",
    "        super(myDataset, self).__init__()\n",
    "        self.y = y.reshape(-1, 1)\n",
    "        \n",
    "        self.origin_shape = X.shape\n",
    "        \n",
    "        # (B, n, T) → (B*T, n)\n",
    "        X_2d = X.reshape(-1, self.origin_shape[1]) \n",
    "        \n",
    "        #训练模式，同时完成 拟合（计算均值和标准差） 和 转换（应用标准化）\n",
    "        if is_train: \n",
    "            self.scaler = StandardScaler()\n",
    "            X_trans = self.scaler.fit_transform(X_2d)\n",
    "            #X_trans = np.clip(X_trans, -5, 5)  # 限制标准化后的值在±5个标准差内\n",
    "        \n",
    "        #验证/测试模式，仅进行 转换（应用标准化），不重新计算均值和标准差\n",
    "        #预先计算好的均值和标准差存储在标准化器（StandardScaler）的内部属性中\n",
    "        \n",
    "        else: \n",
    "            self.scaler = scaler\n",
    "            X_trans = self.scaler.transform(X_2d)\n",
    "            \n",
    "        self.X = X_trans.reshape(self.origin_shape)\n",
    "        self.X = torch.as_tensor(self.X, dtype=torch.float32)\n",
    "        self.y = torch.as_tensor(self.y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    def get_scaler(self):\n",
    "        return self.scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b83beee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alphanet = AlphaNet(d=10, stride=10, n=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5e78b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alphanet(torch.tensor(X[:5]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a435987",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dates = np.array([datetime.strptime(str(date), '%Y-%m-%d').date() for date in dates])\n",
    "unique_dates = sorted(np.unique(target_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "185a493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#用于得到不同的轮次,确保每个轮次为1626天\n",
    "\n",
    "start_dates = []\n",
    "starts, valid_starts, test_starts, ends,  = [], [], [], []\n",
    "\n",
    "i, start, end = 0, 0, 0\n",
    "\n",
    "k = int(1500*0.5) #按1：1划分训练集和测试集\n",
    "\n",
    "while i + 1500 + 126 <= len(unique_dates):\n",
    "    start_dates.append(i)\n",
    "    \n",
    "    start = sum(target_dates < unique_dates[i])\n",
    "    starts.append(start)\n",
    "    \n",
    "    valid_start = sum(target_dates < unique_dates[i+k]) #训练集终点\n",
    "    valid_starts.append(valid_start)\n",
    "    \n",
    "    test_start = sum(target_dates < unique_dates[i+1500]) #验证集重点（1500天）\n",
    "    test_starts.append(test_start)\n",
    "    \n",
    "    end = sum(target_dates < unique_dates[i+1500+126]) #测试集终点（再126天）\n",
    "    ends.append(end)\n",
    "    \n",
    "    i += 126"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1791434",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e84d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "只对X进行窗口标准化\n",
    "'''\n",
    "#### 设置随机种子，保证训练结果一致\n",
    "torch.manual_seed(42)\n",
    "#torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# 设置训练参数：学习率、训练迭代次数、批量大小\n",
    "lr = 0.0001\n",
    "n_epoch = 100\n",
    "batch_size = 1000\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model_name = 'alphanet'\n",
    "\n",
    "# 初始化一个字典，用来储存模型训练期间的表现\n",
    "results = {}\n",
    "results['round'] = []\n",
    "results['train'] = []\n",
    "results['valid'] = []\n",
    "results['test'] = []\n",
    "\n",
    "# 维护 cnt 变量，记录当前是第几个训练轮次\n",
    "cnt = 0\n",
    "\n",
    "# 滚动窗口\n",
    "for start, valid_start, test_start, end in zip(starts, valid_starts, test_starts, ends):\n",
    "    \n",
    "    # 初始化损失函数和优化器\n",
    "    net = AlphaNet(d=10, stride=10, n=9)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=lr)\n",
    "    \n",
    "    # 划分集\n",
    "    train_set = myDataset(X[start:valid_start], Y[start:valid_start], is_train=True)\n",
    "    train_scaler = train_set.get_scaler()\n",
    "    \n",
    "    valid_set = myDataset(X[valid_start:test_start], Y[valid_start:test_start], scaler = train_scaler, is_train=False)\n",
    "    \n",
    "    test_set = myDataset(X[test_start:end], Y[test_start:end], scaler = train_scaler, is_train=False)\n",
    "\n",
    "    # 创建loader\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # 当前训练轮次的模型储存地址\n",
    "    model_path = 'Models_v1/' + model_name + '_' + str(cnt) + '.pt'\n",
    "    \n",
    "    count = 0\n",
    "    train_loss_lst, valid_loss_lst = [], []\n",
    "    best_valid_loss = float('inf')\n",
    "    patience = 10\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        # 训练\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        total_samples = 0\n",
    "        for x, y in tqdm(train_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = net(x)\n",
    "            loss = criterion(preds, y)\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "            total_samples += x.size(0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss /= total_samples\n",
    "        \n",
    "        # 验证\n",
    "        net.eval()\n",
    "        valid_loss = 0\n",
    "        total_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in tqdm(valid_loader):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                preds = net(x)\n",
    "                loss = criterion(preds, y)\n",
    "                valid_loss += loss.item() * x.size(0)\n",
    "                total_samples += x.size(0)\n",
    "        valid_loss /= total_samples\n",
    "\n",
    "        # 监测训练效果\n",
    "        print(\"Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}\".format(epoch+1, train_loss, valid_loss))\n",
    "        \n",
    "        # 记录训练效果\n",
    "        train_loss_lst.append(train_loss)\n",
    "        valid_loss_lst.append(valid_loss)\n",
    "        \n",
    "        # 更新本地模型\n",
    "        if valid_loss < best_valid_loss * 0.999:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "            print(\"Saved model with validation loss of {:.4f}\".format(best_valid_loss)) \n",
    "            count = 0\n",
    "        else:\n",
    "            count += 1\n",
    "            \n",
    "        # 早停：若累计有patience次迭代，模型都没有进步，停止本轮训练\n",
    "        if count >= patience:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    # 记录当前训练轮次的指标变动，并更新本地储存结果\n",
    "    results['round'].append(str(cnt))          \n",
    "    results['train'].append(train_loss_lst)   \n",
    "    results['valid'].append(valid_loss_lst)   \n",
    "    with open(f'Models_v1/train_results_{cnt}.pickle', 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "    \n",
    "    # 下一轮\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77372bd0",
   "metadata": {},
   "source": [
    "# 查看轮次对应的时间区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bc31a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_range(round_idx):\n",
    "    # 获取指定轮次的时间区间\n",
    "    train_start_date = dates[starts[round_idx]]\n",
    "    valid_start_date = dates[valid_starts[round_idx]]\n",
    "    test_start_date = dates[test_starts[round_idx]]\n",
    "    test_end_date = dates[ends[round_idx]]\n",
    "    \n",
    "    return {\n",
    "        \"train\": (train_start_date, valid_start_date),\n",
    "        \"valid\": (valid_start_date, test_start_date),\n",
    "        \"test\": (test_start_date, test_end_date)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab5323cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "训练集: 2011-04-06 至 2014-05-12\n",
      "验证集: 2014-05-12 至 2017-06-07\n",
      "测试集: 2017-06-07 至 2017-12-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_range = get_time_range(0)\n",
    "print(f\"\"\"\n",
    "训练集: {time_range['train'][0]} 至 {time_range['train'][1]}\n",
    "验证集: {time_range['valid'][0]} 至 {time_range['valid'][1]}\n",
    "测试集: {time_range['test'][0]} 至 {time_range['test'][1]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccfac8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af2510a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b9a664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
