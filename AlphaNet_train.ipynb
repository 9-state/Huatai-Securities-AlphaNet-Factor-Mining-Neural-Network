{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b349dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from audtorch.metrics.functional import pearsonr\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2ff734",
   "metadata": {},
   "source": [
    "# 自定义卷积核(特征提取)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee78149",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "过去d天X值构成的时序数列和Y值构成的时序数列的相关系数\n",
    "'''\n",
    "\n",
    "class ts_corr(nn.Module):\n",
    "    def __init__(self, d=10, stride=10):\n",
    "        super(ts_corr, self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, X): #X:3D\n",
    "        B, n, T = X.shape # 批量大小，特征数量，时间窗口长度\n",
    "        \n",
    "        w = (T - self.d) // self.stride + 1  # 窗口数量,例如T=10，d=3，stride=2时，w=4\n",
    "        h = n * (n - 1) // 2  # 特征对的数量 C(n, 2)\n",
    "\n",
    "        # 使用 unfold 提取滑动窗口 [形状: (B, n, w, d)]\n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        \n",
    "        #生成C(n,2)组合数\n",
    "        #例如当n=3时，rows = tensor([0,0,1]), cols = tensor([1,2,2])\n",
    "        rows, cols = torch.triu_indices(n, n, offset=1)\n",
    "\n",
    "        # 提取特征对数据得到x和y [形状: (B, h, w, d)]，分别对应batch维度，特征维度，窗口维度，时间维度\n",
    "        #x为([[:,0,:,:],[:,0,:,:],[:,1,:,:])\n",
    "        #y为([[:,1,:,:],[:,2,:,:],[:,2,:,:])\n",
    "        \n",
    "        x = unfolded_X[:, rows, :, :]\n",
    "        y = unfolded_X[:, cols, :, :]\n",
    "        \n",
    "        x_mean = torch.mean(x, dim=3, keepdim=True) #keepdim维持原本维度不变,在维度3做mean\n",
    "        y_mean = torch.mean(y, dim=3, keepdim=True)\n",
    "        \n",
    "        cov = ((x-x_mean)*(y-y_mean)).sum(dim=3) #(B, h, w)\n",
    "        corr = cov / (torch.std(x, dim=3) * torch.std(y, dim=3)+ 1e-8) #分母添加极小值防止除零错误\n",
    "\n",
    "        return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101be042",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "过去d天X值构成的时序数列和Y值构成的时序数列的协方差\n",
    "'''\n",
    "\n",
    "class ts_cov(nn.Module):\n",
    "    def __init__(self, d=10, stride=10):\n",
    "        super(ts_cov, self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, X):\n",
    "        B, n, T = X.shape \n",
    "        \n",
    "        w = (T - self.d) // self.stride + 1  \n",
    "        h = n * (n - 1) // 2  \n",
    "\n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        \n",
    "        rows, cols = torch.triu_indices(n, n, offset=1)\n",
    "\n",
    "        x = unfolded_X[:, rows, :, :]\n",
    "        y = unfolded_X[:, cols, :, :]\n",
    "        \n",
    "        x_mean = torch.mean(x, dim=3, keepdim=True)\n",
    "        y_mean = torch.mean(y, dim=3, keepdim=True)\n",
    "        \n",
    "        cov = ((x-x_mean)*(y-y_mean)).sum(dim=3) \n",
    "\n",
    "        return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ba47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "过去d天X值构成的时序数列的标准差\n",
    "'''\n",
    "\n",
    "class ts_stddev(nn.Module):\n",
    "    \n",
    "    def __init__(self, d = 10, stride = 10):\n",
    "        super(ts_stddev,self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #input:(B,n,T)，在T维度用unfold展开窗口，变为(B,n,w,d),w为窗口数量会自动计算\n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        #在每个窗口，即d维度上进行std计算\n",
    "        std = torch.std(unfolded_X, dim=3) #输出形状为(B,n,w)\n",
    "        \n",
    "        return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5c0d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "过去d天X值构成的时序数列的平均值除以标准差\n",
    "'''\n",
    "\n",
    "class ts_zscore(nn.Module):\n",
    "    \n",
    "    def __init__(self, d = 10, stride = 10):\n",
    "        super(ts_zscore,self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        \n",
    "        mean = torch.mean(unfolded_X, dim=3)\n",
    "        std = torch.std(unfolded_X, dim=3)\n",
    "        zscore = mean / (std + 1e-8)\n",
    "        \n",
    "        return zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8df1a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "研报原话为：\n",
    "(X - delay(X, d))/delay(X, d)-1, delay(X, d)为 X 在 d 天前的取值\n",
    "这里可能有误，return为“收益率“，应该是误加了-1\n",
    "为了保持代码一致性，这里计算的是(X - delay(X, d-1))/delay(X, d-1),  delay(X, d-1)为 X 在 d-1 天前的取值\n",
    "在构造卷积核的逻辑上是相似的\n",
    "'''\n",
    "\n",
    "class ts_return(nn.Module):\n",
    "    \n",
    "    def __init__(self, d = 10, stride = 10):\n",
    "        super(ts_return,self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        return1 = unfolded_X[:,:,:,-1] /(unfolded_X[:,:,:,0] + 1e-8) - 1\n",
    "        \n",
    "        return return1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0496fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "过去d天X值构成的时序数列的加权平均值，权数为d, d – 1, …, 1(权数之和应为1，需进行归一化处理）\n",
    "其中离现在越近的日子权数越大。 \n",
    "'''\n",
    "\n",
    "class ts_decaylinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, d = 10, stride = 10):\n",
    "        super(ts_decaylinear,self).__init__()\n",
    "        self.d = d\n",
    "        self.stride = stride\n",
    "        #如下设计的权重系数满足离现在越近的日子权重越大\n",
    "        weights = torch.arange(d, 0, -1, dtype = torch.float32) \n",
    "        weights = weights / weights.sum()\n",
    "        #注册权重，不用在前向传播函数中重复计算\n",
    "        #注册了一个形状为(d,)的一维张量，存放权重系数，以便在forward函数中使用\n",
    "        self.register_buffer('weights', weights) \n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        unfolded_X = X.unfold(2, self.d, self.stride)\n",
    "        #view将一维张量广播为4D张量，并在时间维度上，将weights与unfoled_X相乘\n",
    "        decaylinear = torch.sum(unfolded_X * self.weights.view(1,1,1,-1), dim=-1)\n",
    "        \n",
    "        return decaylinear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a4748",
   "metadata": {},
   "source": [
    "# 神经网络结构设计 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5097af",
   "metadata": {},
   "source": [
    "原始路径(RawPath)：特征提取层→BN\n",
    "\n",
    "池化路径(PoolPath)：特征提取层→池化层→BN\n",
    "\n",
    "展平→全连接层→预测目标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c5434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "原始路径：特征提取层+BN\n",
    "'''\n",
    "class RawPath(nn.Module):\n",
    "    def __init__(self, extractor, bn_dim): #传入参数：卷积核，特征维度\n",
    "        super().__init__()\n",
    "        self.extractor = extractor\n",
    "        self.bn = nn.BatchNorm1d(bn_dim)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        x = self.extractor(X) #extract\n",
    "        x = self.bn(x) #BN\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e1a250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "池化路径：特征提取层+池化层+BN\n",
    "'''\n",
    "class PoolPath(nn.Module): #传入参数：卷积核，特征维度\n",
    "    def __init__(self, extractor, bn_dim, d_pool=3, s_pool=3):\n",
    "        super().__init__()\n",
    "        self.extractor = extractor\n",
    "        \n",
    "        self.avg_pool = nn.AvgPool1d(d_pool, s_pool)\n",
    "        self.max_pool = nn.MaxPool1d(d_pool, s_pool)\n",
    "        \n",
    "        #每个池化操作bihv使用独立的 BatchNorm 层\n",
    "        #否则会导致三种不同统计量（均值、最大值、最小值）的分布被强制归一化到同一参数\n",
    "        self.bn_avg = nn.BatchNorm1d(bn_dim) \n",
    "        self.bn_max = nn.BatchNorm1d(bn_dim)\n",
    "        self.bn_min = nn.BatchNorm1d(bn_dim)\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.extractor(X)\n",
    "        \n",
    "        x_avg = self.bn_avg(self.avg_pool(x))\n",
    "        x_max = self.bn_max(self.max_pool(x))\n",
    "        x_min = self.bn_min(-self.max_pool(-x))#手动取反实现min_pool\n",
    "        \n",
    "        return torch.cat([x_avg, x_max, x_min], dim = 1) #在特征维度进行拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ff467db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaNet(nn.Module):\n",
    "\n",
    "    def __init__(self, d=10, stride=10, d_pool=3, s_pool=3, n=9, T=30): #池化层窗口d=3，步长stride=3\n",
    "        super(AlphaNet, self).__init__()\n",
    "        \n",
    "        self.d = d \n",
    "        self.stride = stride \n",
    "        h = n * (n - 1) // 2 #手动计算cov和corr特征提取后的特征维度大小\n",
    "        w = (T - d) // stride + 1 #手动计算特征提取层窗口数\n",
    "        w_pool = (w - d_pool) // s_pool + 1 #手动计算池化层窗口数\n",
    "        \n",
    "        #特征提取层列表，共7个\n",
    "        self.extractors = nn.ModuleList([\n",
    "            ts_corr(d,stride),\n",
    "            ts_cov(d,stride),\n",
    "            ts_stddev(d,stride),\n",
    "            ts_zscore(d,stride),\n",
    "            ts_return(d,stride),\n",
    "            ts_decaylinear(d,stride),\n",
    "            nn.AvgPool1d(d,stride) #原研报中的ts_mean\n",
    "        ])\n",
    "        \n",
    "\n",
    "        # 初始化双路径\n",
    "        self.raw_paths = nn.ModuleList()\n",
    "        self.pool_paths = nn.ModuleList()\n",
    "        \n",
    "        # 前两个特征提取器使用h维BN\n",
    "        for i in range(2):\n",
    "            self.raw_paths.append(RawPath(self.extractors[i], h))\n",
    "            self.pool_paths.append(PoolPath(self.extractors[i], h))\n",
    "        \n",
    "        # 后五个特征提取器使用n维BN\n",
    "        for i in range(2, 7):\n",
    "            self.raw_paths.append(RawPath(self.extractors[i], n))\n",
    "            self.pool_paths.append(PoolPath(self.extractors[i], n))\n",
    "\n",
    "        raw_dim = (2*h + 5*n)*w #计算初始路径展平后的维度\n",
    "        pooled_dim = (h*2*3 + n*5*3)*w_pool #计算池化路径展平后的维度\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(raw_dim + pooled_dim, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(30, 1)\n",
    "        )\n",
    "\n",
    "        # 初始化\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                \n",
    "                #截断正态初始化\n",
    "                fan_in = m.weight.size(1)\n",
    "                std = math.sqrt(1.0 / fan_in)  # Xavier方差标准\n",
    "                nn.init.trunc_normal_(m.weight, std=std, a=-2*std, b=2*std)\n",
    "                nn.init.normal_(m.bias, std=1e-6)\n",
    "                \n",
    "                #Kaiming初始化\n",
    "                #nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                \n",
    "                #Xavier初始化\n",
    "                #nn.init.xavier_uniform_(m.weight)\n",
    "                #nn.init.normal_(m.bias, std=1e-6)\n",
    "            \n",
    "    def forward(self, X):\n",
    "        \n",
    "        raw_features = [path(X).flatten(1) for path in self.raw_paths] #原始路径得到的张量进行展平\n",
    "        pool_features = [path(X).flatten(1) for path in self.pool_paths] #池化路径得到的张量进行展平\n",
    "        all_features = torch.cat(raw_features + pool_features, dim=1) \n",
    "        \n",
    "        return self.head(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab419bff",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95e9ec6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (930008, 9, 30)\n",
      "Shape of Y:  (930008,)\n"
     ]
    }
   ],
   "source": [
    "X = np.load('npy_v1/X_fe.npy')\n",
    "Y = np.load('npy_v1/Y_fe.npy')\n",
    "dates = np.load('npy_v1/Y_dates.npy')\n",
    "\n",
    "print('Shape of X: ', X.shape)\n",
    "print('Shape of Y: ', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ec8eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "对X进行窗口标准化\n",
    "'''\n",
    "class myDataset(Dataset):\n",
    "    '''\n",
    "    自定义数据集，将原始数据从 numpy arrays 转换成 float 格式的 tensors\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, X, y, scaler = None, is_train = True):\n",
    "        super(myDataset, self).__init__()\n",
    "        self.y = y.reshape(-1, 1)\n",
    "        \n",
    "        self.origin_shape = X.shape\n",
    "        \n",
    "        # (B, n, T) → (B*T, n)\n",
    "        X_2d = X.reshape(-1, self.origin_shape[1]) \n",
    "        \n",
    "        #训练模式，同时完成 拟合（计算均值和标准差） 和 转换（应用标准化）\n",
    "        if is_train: \n",
    "            self.scaler = StandardScaler()\n",
    "            X_trans = self.scaler.fit_transform(X_2d)\n",
    "            #X_trans = np.clip(X_trans, -5, 5)  # 限制标准化后的值在±5个标准差内\n",
    "        \n",
    "        #验证/测试模式，仅进行 转换（应用标准化），不重新计算均值和标准差\n",
    "        #预先计算好的均值和标准差存储在标准化器（StandardScaler）的内部属性中\n",
    "        \n",
    "        else: \n",
    "            self.scaler = scaler\n",
    "            X_trans = self.scaler.transform(X_2d)\n",
    "            \n",
    "        self.X = X_trans.reshape(self.origin_shape)\n",
    "        self.X = torch.as_tensor(self.X, dtype=torch.float32)\n",
    "        self.y = torch.as_tensor(self.y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    def get_scaler(self):\n",
    "        return self.scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24c438a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alphanet = AlphaNet(d=10, stride=10, n=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "865323c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alphanet(torch.tensor(X[:5]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85329938",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dates = np.array([datetime.strptime(str(date), '%Y-%m-%d').date() for date in dates])\n",
    "unique_dates = sorted(np.unique(target_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b28cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#用于得到不同的轮次,确保每个轮次为1626天\n",
    "\n",
    "start_dates = []\n",
    "starts, valid_starts, test_starts, ends,  = [], [], [], []\n",
    "\n",
    "i, start, end = 0, 0, 0\n",
    "\n",
    "k = int(1500*0.5) #按1：1划分训练集和测试集\n",
    "\n",
    "while i + 1500 + 126 <= len(unique_dates):\n",
    "    start_dates.append(i)\n",
    "    \n",
    "    start = sum(target_dates < unique_dates[i])\n",
    "    starts.append(start)\n",
    "    \n",
    "    valid_start = sum(target_dates < unique_dates[i+k]) #训练集终点\n",
    "    valid_starts.append(valid_start)\n",
    "    \n",
    "    test_start = sum(target_dates < unique_dates[i+1500]) #验证集重点（1500天）\n",
    "    test_starts.append(test_start)\n",
    "    \n",
    "    end = sum(target_dates < unique_dates[i+1500+126]) #测试集终点（再126天）\n",
    "    ends.append(end)\n",
    "    \n",
    "    i += 126"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e2112",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af809fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.84it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.0072, Validation Loss: 0.0075\n",
      "Saved model with validation loss of 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 0.0017, Validation Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:12<00:00, 10.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Training Loss: 0.0010, Validation Loss: 0.0048\n",
      "Saved model with validation loss of 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.87it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Training Loss: 0.0009, Validation Loss: 0.0037\n",
      "Saved model with validation loss of 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Training Loss: 0.0008, Validation Loss: 0.0025\n",
      "Saved model with validation loss of 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Training Loss: 0.0007, Validation Loss: 0.0022\n",
      "Saved model with validation loss of 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Training Loss: 0.0007, Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Training Loss: 0.0007, Validation Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.81it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Training Loss: 0.0007, Validation Loss: 0.0018\n",
      "Saved model with validation loss of 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss: 0.0007, Validation Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Training Loss: 0.0007, Validation Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.87it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Training Loss: 0.0007, Validation Loss: 0.0017\n",
      "Saved model with validation loss of 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.78it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Training Loss: 0.0007, Validation Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Training Loss: 0.0007, Validation Loss: 0.0016\n",
      "Saved model with validation loss of 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.80it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Training Loss: 0.0007, Validation Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Training Loss: 0.0007, Validation Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.81it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Training Loss: 0.0007, Validation Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Training Loss: 0.0007, Validation Loss: 0.0015\n",
      "Saved model with validation loss of 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Training Loss: 0.0007, Validation Loss: 0.0015\n",
      "Saved model with validation loss of 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Training Loss: 0.0007, Validation Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:12<00:00, 10.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Training Loss: 0.0007, Validation Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:12<00:00,  9.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Training Loss: 0.0007, Validation Loss: 0.0015\n",
      "Saved model with validation loss of 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:12<00:00, 10.53it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Training Loss: 0.0007, Validation Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:12<00:00, 10.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Training Loss: 0.0007, Validation Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.59it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Training Loss: 0.0007, Validation Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:12<00:00, 10.51it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Training Loss: 0.0007, Validation Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:12<00:00, 10.53it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Training Loss: 0.0007, Validation Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.79it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Training Loss: 0.0007, Validation Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:12<00:00, 10.46it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Training Loss: 0.0007, Validation Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Training Loss: 0.0007, Validation Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:12<00:00, 10.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Training Loss: 0.0007, Validation Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [00:12<00:00, 10.29it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 143/143 [00:11<00:00, 12.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Training Loss: 0.0007, Validation Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 130/130 [00:11<00:00, 10.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 152/152 [00:12<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.0231, Validation Loss: 0.0309\n",
      "Saved model with validation loss of 0.0309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 130/130 [00:12<00:00, 10.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 152/152 [00:12<00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 0.0031, Validation Loss: 0.0272\n",
      "Saved model with validation loss of 0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 130/130 [00:12<00:00, 10.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 152/152 [00:12<00:00, 12.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Training Loss: 0.0019, Validation Loss: 0.0073\n",
      "Saved model with validation loss of 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 130/130 [00:12<00:00, 10.80it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 152/152 [00:12<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Training Loss: 0.0012, Validation Loss: 0.0059\n",
      "Saved model with validation loss of 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 130/130 [00:12<00:00, 10.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 152/152 [00:12<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Training Loss: 0.0009, Validation Loss: 0.0051\n",
      "Saved model with validation loss of 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 130/130 [00:12<00:00, 10.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 152/152 [00:12<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Training Loss: 0.0009, Validation Loss: 0.0829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 130/130 [00:12<00:00, 10.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 152/152 [00:12<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Training Loss: 0.0008, Validation Loss: 0.0043\n",
      "Saved model with validation loss of 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 130/130 [00:12<00:00, 10.53it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 152/152 [00:12<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Training Loss: 0.0007, Validation Loss: 0.0039\n",
      "Saved model with validation loss of 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 130/130 [00:12<00:00, 10.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 152/152 [00:12<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Training Loss: 0.0007, Validation Loss: 0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 130/130 [00:12<00:00, 10.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 152/152 [00:12<00:00, 12.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss: 0.0007, Validation Loss: 0.0855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 130/130 [00:12<00:00, 10.53it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 152/152 [00:12<00:00, 12.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Training Loss: 0.0007, Validation Loss: 0.0297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 130/130 [00:12<00:00, 10.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 152/152 [00:12<00:00, 12.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Training Loss: 0.0007, Validation Loss: 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 130/130 [00:12<00:00, 10.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 152/152 [00:12<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Training Loss: 0.0007, Validation Loss: 0.0450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 130/130 [00:12<00:00, 10.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 152/152 [00:12<00:00, 12.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Training Loss: 0.0007, Validation Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 130/130 [00:12<00:00, 10.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 152/152 [00:12<00:00, 12.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Training Loss: 0.0007, Validation Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 130/130 [00:12<00:00, 10.60it/s]\n",
      " 62%|██████████████████████████████████████████████████                               | 94/152 [00:07<00:04, 11.87it/s]"
     ]
    }
   ],
   "source": [
    "'''\n",
    "只对X进行窗口标准化\n",
    "'''\n",
    "#### 设置随机种子，保证训练结果一致\n",
    "torch.manual_seed(42)\n",
    "#torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# 设置训练参数：学习率、训练迭代次数、批量大小\n",
    "lr = 0.0001\n",
    "n_epoch = 100\n",
    "batch_size = 1000\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model_name = 'alphanet'\n",
    "\n",
    "# 初始化一个字典，用来储存模型训练期间的表现\n",
    "results = {}\n",
    "results['round'] = []\n",
    "results['train'] = []\n",
    "results['valid'] = []\n",
    "results['test'] = []\n",
    "\n",
    "# 维护 cnt 变量，记录当前是第几个训练轮次\n",
    "cnt = 0\n",
    "\n",
    "# 滚动窗口\n",
    "for start, valid_start, test_start, end in zip(starts, valid_starts, test_starts, ends):\n",
    "    \n",
    "    # 初始化损失函数和优化器\n",
    "    net = AlphaNet(d=10, stride=10, n=9)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=lr)\n",
    "    \n",
    "    # 划分集\n",
    "    train_set = myDataset(X[start:valid_start], Y[start:valid_start], is_train=True)\n",
    "    train_scaler = train_set.get_scaler()\n",
    "    \n",
    "    valid_set = myDataset(X[valid_start:test_start], Y[valid_start:test_start], scaler = train_scaler, is_train=False)\n",
    "    \n",
    "    test_set = myDataset(X[test_start:end], Y[test_start:end], scaler = train_scaler, is_train=False)\n",
    "\n",
    "    # 创建loader\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # 当前训练轮次的模型储存地址\n",
    "    model_path = 'Models_v1/' + model_name + '_' + str(cnt) + '.pt'\n",
    "    \n",
    "    count = 0\n",
    "    train_loss_lst, valid_loss_lst = [], []\n",
    "    best_valid_loss = float('inf')\n",
    "    patience = 10\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        # 训练\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        total_samples = 0\n",
    "        for x, y in tqdm(train_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = net(x)\n",
    "            loss = criterion(preds, y)\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "            total_samples += x.size(0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss /= total_samples\n",
    "        \n",
    "        # 验证\n",
    "        net.eval()\n",
    "        valid_loss = 0\n",
    "        total_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in tqdm(valid_loader):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                preds = net(x)\n",
    "                loss = criterion(preds, y)\n",
    "                valid_loss += loss.item() * x.size(0)\n",
    "                total_samples += x.size(0)\n",
    "        valid_loss /= total_samples\n",
    "\n",
    "        # 监测训练效果\n",
    "        print(\"Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}\".format(epoch+1, train_loss, valid_loss))\n",
    "        \n",
    "        # 记录训练效果\n",
    "        train_loss_lst.append(train_loss)\n",
    "        valid_loss_lst.append(valid_loss)\n",
    "        \n",
    "        # 更新本地模型\n",
    "        if valid_loss < best_valid_loss * 0.999:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "            print(\"Saved model with validation loss of {:.4f}\".format(best_valid_loss)) \n",
    "            count = 0\n",
    "        else:\n",
    "            count += 1\n",
    "            \n",
    "        # 早停：若累计有patience次迭代，模型都没有进步，停止本轮训练\n",
    "        if count >= patience:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    # 记录当前训练轮次的指标变动，并更新本地储存结果\n",
    "    results['round'].append(str(cnt))          \n",
    "    results['train'].append(train_loss_lst)   \n",
    "    results['valid'].append(valid_loss_lst)   \n",
    "    with open(f'Models_v1/train_results_{cnt}.pickle', 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "    \n",
    "    # 下一轮\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c598bd9",
   "metadata": {},
   "source": [
    "# 查看轮次对应的时间区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cbd25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_range(round_idx):\n",
    "    # 获取指定轮次的时间区间\n",
    "    train_start_date = unique_dates[starts[round_idx]]\n",
    "    valid_start_date = unique_dates[valid_starts[round_idx]]\n",
    "    test_start_date = unique_dates[test_starts[round_idx]]\n",
    "    test_end_date = unique_dates[ends[round_idx]]\n",
    "    \n",
    "    return {\n",
    "        \"train\": (train_start_date, valid_start_date - timedelta(days=1)),\n",
    "        \"valid\": (valid_start_date, test_start_date - timedelta(days=1)),\n",
    "        \"test\": (test_start_date, test_end_date)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a13e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = get_time_range(2)\n",
    "print(f\"\"\"\n",
    "训练集: {time_range['train'][0]} 至 {time_range['train'][1]}\n",
    "验证集: {time_range['valid'][0]} 至 {time_range['valid'][1]}\n",
    "测试集: {time_range['test'][0]} 至 {time_range['test'][1]}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
